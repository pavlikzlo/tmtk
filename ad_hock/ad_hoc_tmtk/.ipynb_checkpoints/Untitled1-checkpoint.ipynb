{
 "metadata": {
  "name": "",
  "signature": "sha256:eff6dec6081102238ca7a1965055f82d0a7204ebb226de8369b6ecf1d9339849"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "\n",
      "from numpy import *\n",
      "import pandas as pd\n",
      "\n",
      "from itertools import izip_longest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 196
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grouper(iterable, n, fillvalue=None):\n",
      "    args = [iter(iterable)] * n\n",
      "    return izip_longest(*args, fillvalue=fillvalue)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read(f_name):\n",
      "    doc_count, wrd_count, str_documents = open(f_name).read().split('\\n', 2)\n",
      "\n",
      "    documents = []\n",
      "    for _, words, counts in grouper(str_documents.split('\\n')[:-1], 3):\n",
      "        words, counts = map(int, words.split()), map(int, counts.split())\n",
      "        documents.append(array(zip(words, counts)))\n",
      "    \n",
      "    return int(doc_count), int(wrd_count), array(documents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_, _, documents_train = read('NIPS-collection/NIPSOld_t.txt')\n",
      "_, _, documents_test = read('NIPS-collection/NIPSOld_c.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def norn_mtx(x, y, axis):\n",
      "    mtx = random.random((x, y))\n",
      "    for row in mtx.T if axis == 'x' else mtx: \n",
      "        row /= row.sum()\n",
      "    return mtx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def preplexity(F, T, documents):\n",
      "    doc_count, wrd_count = len(T[0]), len(F[0])\n",
      "    lh = 0\n",
      "    for d in xrange(doc_count):\n",
      "        for w, ndw in documents[d]:\n",
      "            lh += ndw * log(dot(F[w, :], T[:, d]))\n",
      "    return e ** (-lh / sum([sum([ndw for _, ndw in documents[d]]) for d in xrange(doc_count)]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def half_random(documents_test):\n",
      "    estimat_doc, control_doc = [], []\n",
      "    for d in documents_test:\n",
      "        est_d, con_d = [], []\n",
      "        for w, wrdc in d:\n",
      "            if wrdc > 1:\n",
      "                est_d.append((w, wrdc/2))\n",
      "                con_d.append((w, wrdc/2))\n",
      "            else:\n",
      "                if randint(0, 100) % 2:\n",
      "                    est_d.append((w, wrdc/2))\n",
      "                else:\n",
      "                    con_d.append((w, wrdc/2))\n",
      "        estimat_doc.append(array(est_d))\n",
      "        control_doc.append(array(con_d))\n",
      "        \n",
      "    return array(estimat_doc), array(control_doc)\n",
      "\n",
      "def estimate_teta(F, documents_test, num_topics=100):\n",
      "    doc_count = len(documents_test)\n",
      "    T = zeros((num_topics, doc_count))\n",
      "    \n",
      "    estimate_doc, control_doc = half_random(documents_test)\n",
      "\n",
      "    for d in range(doc_count):\n",
      "        for w, wrd_count in estimate_doc[d]:\n",
      "            T.T[d] += (F[w] * wrd_count)\n",
      "            \n",
      "    for row in T.T: \n",
      "        row /= row.sum()\n",
      "            \n",
      "    return T, control_doc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plsa_em(documents_train, documents_test=None, num_topics=100, num_itter=10, metric=preplexity):\n",
      "    doc_count, wrd_count = len(documents_train), len(set([wrd for doc in documents_train for wrd, _ in doc]))\n",
      "    F, T = norn_mtx(wrd_count, num_topics, axis='x'), norn_mtx(num_topics, doc_count, axis='y')\n",
      "    \n",
      "    for itter in xrange(num_itter):\n",
      "        Nwt, Ntd, Nt, Nd = zeros((wrd_count, num_topics)), zeros((num_topics, doc_count)), zeros(num_topics), zeros(doc_count)\n",
      "        \n",
      "        for d in xrange(doc_count):\n",
      "            for w, ndw in documents_train[d]:\n",
      "                ndwt = F[w, :] * T[:, d]\n",
      "                ndwt *= ndw * (1.0/ndwt.sum())\n",
      "                \n",
      "                Nwt[w] += ndwt\n",
      "                Ntd[:, d] += ndwt\n",
      "                Nt += ndwt\n",
      "                Nd[d] += ndwt.sum()\n",
      "\n",
      "                \n",
      "        for w in xrange(wrd_count):\n",
      "            F[w] = Nwt[w] / Nt\n",
      "            \n",
      "        for t in range(num_topics):\n",
      "            T[t] = Ntd[t] / Nd\n",
      "            \n",
      "        Ti, docs = estimate_teta(F, documents_test)\n",
      "            \n",
      "        print 'itter %s prepl: train = %.2f, test = %.2f' % (itter, metric(F, T, documents_train), metric(F, Ti, docs))\n",
      "        sys.stdout.flush()\n",
      "        \n",
      "    return F, T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 203
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time F, T = plsa_em(documents_train, documents_test, num_itter=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "itter 0 prepl: train = 2858.01, test = 2261.72\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "itter 1 prepl: train = 2831.82, test = 2260.86\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "itter 2 prepl: train = 2803.05, test = 2259.10\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "itter 3 prepl: train = 2767.15, test = 2255.94\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "itter 4 prepl: train = 2718.01, test = 2250.29\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "itter 5 prepl: train = 2646.89, test = 2240.04\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "itter 6 prepl: train = 2543.75, test = 2221.59\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "itter 7 prepl: train = 2404.02, test = 2190.58\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "itter 8 prepl: train = 2238.43, test = 2145.52\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "itter 9 prepl: train = 2071.23, test = 2091.82\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 11min 42s, sys: 7.03 s, total: 11min 50s\n",
        "Wall time: 12min 4s\n"
       ]
      }
     ],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}