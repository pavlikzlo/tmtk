{
 "metadata": {
  "name": "",
  "signature": "sha256:e55d9f8f0e3348dc813940839b6dbdbe35c9dae63885c55447424324ae3fca9e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "\n",
      "from numpy import *\n",
      "import pandas as pd\n",
      "\n",
      "from itertools import izip_longest\n",
      "from __future__ import division\n",
      "\n",
      "import time\n",
      "import scipy.sparse\n",
      "from math import *\n",
      "\n",
      "from sklearn.decomposition import RandomizedPCA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grouper(iterable, n, fillvalue=None):\n",
      "    args = [iter(iterable)] * n\n",
      "    return izip_longest(*args, fillvalue=fillvalue)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read(f_name):\n",
      "    doc_count, wrd_count, str_documents = open(f_name).read().split('\\n', 2)\n",
      "\n",
      "    documents = []\n",
      "    for _, words, counts in grouper(str_documents.split('\\n')[:-1], 3):\n",
      "        words, counts = map(int, words.split()), map(int, counts.split())\n",
      "        documents.append(array(zip(words, counts)))\n",
      "    \n",
      "    return int(doc_count), int(wrd_count), array(documents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_, _, documents_train = read('NIPS-collection/NIPSOld_t.txt')\n",
      "_, _, documents_test = read('NIPS-collection/NIPSOld_c.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_M_matrix(docs):\n",
      "    docs_count, wrds_count = len(docs), len(set([wrd for doc in docs for wrd, _ in doc]))\n",
      "    M = np.zeros((wrds_count, docs_count))\n",
      "    \n",
      "    for doc in xrange(docs_count):\n",
      "        for wrd, wrd_count in docs[doc]:\n",
      "            M[wrd, doc] = wrd_count\n",
      "    \n",
      "    return M"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = generate_M_matrix(documents_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_Q_matrix(M):\n",
      "    vocabSize, numdocs = M.shape[0], M.shape[1]\n",
      "    diag_M = np.zeros(vocabSize)\n",
      "\n",
      "    for column in M.T:\n",
      "        denom = column.sum() * (column.sum()-1)\n",
      "        diag_M += column * 1.0 / denom\n",
      "        column  /= sqrt(denom)\n",
      "    \n",
      "    Q = (np.dot(M, M.T) - np.diag(diag_M)) / numdocs\n",
      "    \n",
      "    return Q"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q = generate_Q_matrix(M)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}